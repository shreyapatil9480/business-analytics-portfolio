{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bce3801",
   "metadata": {},
   "source": [
    "\n",
    "# Business Analytics Portfolio Project\n",
    "\n",
    "This notebook is part of a portfolio project designed for roles such as **Business Analyst**, **Program Manager**, and **Data Analyst**. It uses a synthetic dataset representing projects with various attributes like duration, budget, cost, team size, complexity, risk, and status. The objectives are to explore the data, perform exploratory data analysis (EDA), visualize key patterns, and build predictive models to understand factors associated with project success.\n",
    "\n",
    "The dataset is completely synthetic and generated for demonstration purposes only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac46382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the synthetic dataset\n",
    "# If running this notebook after cloning the repo, ensure that the CSV file is in the same directory or adjust the path accordingly.\n",
    "df = pd.read_csv('synthetic_project_data.csv', parse_dates=['StartDate','EndDate','ActualEndDate'])\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check data types and missing values\n",
    "print(df.info())\n",
    "print(\"\n",
    "Missing values per column:\n",
    "\", df.isnull().sum())\n",
    "\n",
    "# Summary statistics for numeric columns\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89222ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distribution of planned vs actual durations\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(df['PlannedDurationDays'], kde=True, color='skyblue', label='Planned Duration', bins=20)\n",
    "sns.histplot(df['ActualDurationDays'], kde=True, color='orange', label='Actual Duration', bins=20)\n",
    "plt.title('Distribution of Planned vs Actual Durations')\n",
    "plt.xlabel('Duration (days)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Budget distribution\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['Budget'], kde=True, color='green', bins=20)\n",
    "plt.title('Distribution of Project Budgets')\n",
    "plt.xlabel('Budget')\n",
    "plt.show()\n",
    "\n",
    "# Complexity counts\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Complexity', data=df, order=['Low','Medium','High'])\n",
    "plt.title('Count of Projects by Complexity')\n",
    "plt.show()\n",
    "\n",
    "# Cost variance by risk\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x='Risk', y='CostVariance', data=df, order=['Low','Medium','High'])\n",
    "plt.title('Cost Variance by Risk Level')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap for numeric variables\n",
    "numeric_cols = ['PlannedDurationDays', 'ActualDurationDays', 'Budget', 'ActualCost', 'TeamSize', 'ScheduleVarianceDays', 'CostVariance', 'Success']\n",
    "plt.figure(figsize=(10,8))\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deef127",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare data for modeling\n",
    "# Feature columns: numeric + encoded categorical\n",
    "X = df[['PlannedDurationDays','ActualDurationDays','Budget','ActualCost','TeamSize','Complexity','Risk','ScheduleVarianceDays','CostVariance']]\n",
    "y = df['Success']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "categorical_cols = ['Complexity', 'Risk']\n",
    "numeric_cols = ['PlannedDurationDays','ActualDurationDays','Budget','ActualCost','TeamSize','ScheduleVarianceDays','CostVariance']\n",
    "\n",
    "# Preprocess: OneHotEncode categorical variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols),\n",
    "        ('num', 'passthrough', numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create pipeline with logistic regression model\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")\n",
    "print(\"\n",
    "Classification Report:\n",
    "\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\n",
    "\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Define features and target for regression\n",
    "X_reg = df[['PlannedDurationDays','ActualDurationDays','Budget','TeamSize','Complexity','Risk','ScheduleVarianceDays']]\n",
    "y_reg = df['ActualCost']\n",
    "\n",
    "# Train-test split\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.25, random_state=42)\n",
    "\n",
    "# Preprocess (same as before)\n",
    "preprocessor_reg = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), ['Complexity', 'Risk']),\n",
    "        ('num', 'passthrough', ['PlannedDurationDays','ActualDurationDays','Budget','TeamSize','ScheduleVarianceDays'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline with RandomForestRegressor\n",
    "reg_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_reg),\n",
    "    ('model', RandomForestRegressor(n_estimators=200, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit\n",
    "reg_model.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Predict\n",
    "y_pred_reg = reg_model.predict(X_test_reg)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "print(f\"Random Forest Regression MAE: {mae:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02dbec",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "This analysis demonstrated how to explore a project dataset, visualize key patterns, and build predictive models.\n",
    "\n",
    "**Key takeaways:**\n",
    "\n",
    "- The synthetic dataset contained information about project durations, budgets, costs, team sizes, complexity levels, risk levels, and project outcomes.\n",
    "- Exploratory analysis highlighted distributions and relationships between variables, such as budget and cost variance across risk categories and the prevalence of different complexity levels.\n",
    "- A logistic regression model was built to predict project success, achieving reasonable accuracy. The model can be further improved through feature engineering and experimenting with more sophisticated algorithms.\n",
    "- A random forest regression model was used to predict actual project costs, demonstrating how regression techniques can be applied to project budgeting.\n",
    "\n",
    "Feel free to build upon this project by:\n",
    "\n",
    "- Exploring additional visualizations (e.g., time-series analysis by year).\n",
    "- Trying other classification algorithms (e.g., Random Forest, XGBoost) and comparing performance.\n",
    "- Performing hyperparameter tuning for improved model performance.\n",
    "- Incorporating other synthetic or real-world datasets for a more comprehensive portfolio.\n",
    "\n",
    "This notebook and dataset serve as a solid foundation for demonstrating analytical and modeling skills relevant to business analysis, program management, and data analysis roles.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
